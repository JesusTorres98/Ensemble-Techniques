# Ensemble-Techniques
Overview

In the previous courses, we have studied how to build a predictive model for different scenarios but what if we could combine the decisions from multiple models to make better predictions? In the Ensemble Techniques course, we will learn about ensemble models which use a collection of machine learning models to make predictions, rather than individual models.

Ensemble Techniques course will focus on developing a deep understanding of different ensemble methods like bagging, boosting, and stacking and how to implement these algorithms for classification and regression problems. We will also explore how this technique of combining models improves the overall performance.

Course Objectives

After completing this course, you will be able to:

Understand and appreciate the most widely used Ensemble Technique - Bagging, Boosting, and Stacking.
Focus on problem recognition and build predictive models in the context of business decision-making.
Assess the model performance using different metrics.
Tune models to improve model performance
Prerequisites

Participants are expected to have knowledge of basic concepts such as Decision Trees, Different impurity measures, descriptive statistics.
Working knowledge of important Python libraries such as sklearn, pandas, numpy, matplotlib, and seaborn is required
Participants are expected to be comfortable with installing Python packages and reading the Python documentation  
Topics Covered

Bagging and Random Forest
Introduction to Ensemble techniques
Introduction to Bagging
Sampling with replacements
Introduction to Random Forest
Hand-on Bagging and Random Forest
Boosting
Introduction to Boosting
Boosting algorithms like:
Adaboost
Gradient boost
XGBoost
Hands-on Boosting
Stacking
